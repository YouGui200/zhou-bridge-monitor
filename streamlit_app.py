"""
================================================================================
å·æ¡¥ç»“æ„å¥åº·ç›‘æµ‹ç³»ç»Ÿ - äº‘ç«¯éƒ¨ç½²ç‰ˆ (Strict Standardized Version)
================================================================================
æ ¸å¿ƒä¿®å¤ï¼š
1. å¼ºåˆ¶åˆ—æ˜ å°„ï¼šæ— è®ºè¾“å…¥CSVè¡¨å¤´ä¸ºä½•ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å°†å…¶æ˜ å°„ä¸ºæ ‡å‡†ä¼ æ„Ÿå™¨åç§°ã€‚
   - åº”å˜æ¨¡å¼ -> strain_S-01_micro ... strain_S-04_micro
   - åŠ é€Ÿåº¦æ¨¡å¼ -> accel_A-01_ms2 ...
2. ä¸¥æ ¼å¯¹åº”ç®—æ³•åº“å®šä¹‰çš„ 4/2/1/1 é€šé“æ•°é‡ã€‚
================================================================================
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import sys
import os
import time
import io
from datetime import datetime
import traceback

# =============================================================================
# 1. æ ¸å¿ƒé…ç½®ä¸è·¯å¾„ç³»ç»Ÿ
# =============================================================================

st.set_page_config(
    page_title="å·æ¡¥ç›‘æµ‹ç³»ç»Ÿ",
    page_icon="ğŸŒ‰",
    layout="wide",
    initial_sidebar_state="expanded"
)

CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.append(CURRENT_DIR)
DATA_PATH = CURRENT_DIR

try:
    from preprocessing_lib import (
        MissingValueHandler, NoiseFilter, AnomalyDetector, PerformanceMetrics
    )
    ALGO_STATUS = True
except ImportError:
    ALGO_STATUS = False

# -----------------------------------------------------------------------------
# ä¼ æ„Ÿå™¨é…ç½® (ä¸¥æ ¼å®šä¹‰æ ‡å‡†é€šé“å)
# -----------------------------------------------------------------------------
SENSORS = {
    'strain': {
        'name': 'åº”å˜ä¼ æ„Ÿå™¨', 
        'icon': 'ğŸ”´', 
        'color': '#F44336', 
        'file': 'raw_data_strain.csv', 
        'unit': 'Î¼Îµ',
        # å®šä¹‰æ ‡å‡†é€šé“ååˆ—è¡¨
        'channels': [
            'strain_S-01_micro', 
            'strain_S-02_micro', 
            'strain_S-03_micro', 
            'strain_S-04_micro'
        ],
        'desc': 'ç›‘æµ‹æ‹±é¡¶/æ‹±è„šå—åŠ› (4é€šé“: S-01~S-04)'
    },
    'accel': {
        'name': 'åŠ é€Ÿåº¦ä¼ æ„Ÿå™¨', 
        'icon': 'ğŸ”µ', 
        'color': '#2196F3', 
        'file': 'raw_data_acceleration.csv', 
        'unit': 'm/sÂ²', 
        'channels': [
            'accel_A-01_ms2', 
            'accel_A-02_ms2'
        ],
        'desc': 'ç›‘æµ‹æ¡¥é¢æŒ¯åŠ¨ (2é€šé“: A-01~A-02)'
    },
    'temp': {
        'name': 'æ¸©åº¦ä¼ æ„Ÿå™¨', 
        'icon': 'ğŸŸ¢', 
        'color': '#4CAF50', 
        'file': 'raw_data_temperature.csv', 
        'unit': 'Â°C', 
        'channels': [
            'temperature_T-01_C'
        ],
        'desc': 'ç›‘æµ‹ç¯å¢ƒæ¸©åº¦ (1é€šé“: T-01)'
    },
    'disp': {
        'name': 'ä½ç§»ä¼ æ„Ÿå™¨', 
        'icon': 'ğŸŸ£', 
        'color': '#9C27B0', 
        'file': 'raw_data_displacement.csv', 
        'unit': 'mm', 
        'channels': [
            'displacement_D-01_mm'
        ],
        'desc': 'ç›‘æµ‹æ¡¥å¢©æ²‰é™ (1é€šé“: D-01)'
    }
}

# =============================================================================
# 2. æ ¸å¿ƒé€»è¾‘å·¥å…·å‡½æ•°
# =============================================================================

def apply_style():
    st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Times+New+Roman&display=swap');
        .stApp { font-family: "Times New Roman", sans-serif; background-color: #f8f9fa; }
        [data-testid="stSidebar"] { background-color: #1e272e; }
        [data-testid="stSidebar"] * { color: #dcdde1 !important; font-family: Arial, sans-serif; }
        .card { background: white; padding: 20px; border-radius: 5px; box-shadow: 0 2px 5px rgba(0,0,0,0.05); margin-bottom: 15px; border-top: 3px solid #e1e1e1; }
    </style>
    """, unsafe_allow_html=True)

def standardize_columns(df, sensor_type):
    """
    æ ¸å¿ƒä¿®å¤é€»è¾‘ï¼š
    å¼ºåˆ¶å°†æ•°æ®åˆ—é‡å‘½åä¸ºç³»ç»Ÿé¢„è®¾çš„æ ‡å‡†åç§° (å¦‚ strain_S-01_micro)ï¼Œ
    ç¡®ä¿ä¸‹æ‹‰æ¡†æ˜¾ç¤ºçš„æ°¸è¿œæ˜¯æ ‡å‡†åç§°ã€‚
    """
    if df is None: return None
    
    # 1. è¯†åˆ«æ—¶é—´åˆ—
    cols = df.columns.tolist()
    time_col = None
    data_cols = []
    
    exclude_keywords = ['time', 'date', 'timestamp', 'unnamed', 'id', 'index']
    
    for c in cols:
        if any(k in c.lower() for k in exclude_keywords):
            time_col = c
        else:
            data_cols.append(c)
    
    # 2. è·å–è¯¥ä¼ æ„Ÿå™¨ç±»å‹åº”æœ‰çš„æ ‡å‡†åˆ—å
    expected_channels = SENSORS[sensor_type]['channels']
    
    # 3. å»ºç«‹é‡å‘½åæ˜ å°„
    rename_map = {}
    
    # å¦‚æœæ‰¾åˆ°äº†æ—¶é—´åˆ—ï¼Œä¿ç•™å®ƒ
    if time_col:
        # ç¡®ä¿æ—¶é—´åˆ—åç»Ÿä¸€ï¼Œæ–¹ä¾¿åç»­å¤„ç†ï¼ˆå¯é€‰ï¼Œè¿™é‡Œä¿æŒåŸæ ·ï¼‰
        pass
    
    # å¼ºåˆ¶æ˜ å°„æ•°æ®åˆ—
    # å¦‚æœæ•°æ®åˆ—æ•°é‡ <= æ ‡å‡†é€šé“æ•°ï¼ŒæŒ‰é¡ºåºèµ‹äºˆæ ‡å‡†å
    # å¦‚æœæ•°æ®åˆ—æ•°é‡ > æ ‡å‡†é€šé“æ•°ï¼Œåªå–å‰Nä¸ª
    count = min(len(data_cols), len(expected_channels))
    
    for i in range(count):
        original_col = data_cols[i]
        new_name = expected_channels[i]
        rename_map[original_col] = new_name
        
    # æ‰§è¡Œé‡å‘½å
    new_df = df.rename(columns=rename_map)
    
    # æç¤ºä¿¡æ¯ (ä»…è°ƒè¯•ç”¨)
    # print(f"Renamed {rename_map}")
    
    return new_df

def get_display_columns(df):
    """è·å–ç”¨äºæ˜¾ç¤ºçš„åˆ—ï¼ˆæ’é™¤æ—¶é—´åˆ—ï¼‰"""
    if df is None: return []
    cols = df.columns.tolist()
    # åªè¦ä¸åŒ…å«time/date/timestampå­—æ ·ï¼Œä¸”åœ¨æˆ‘ä»¬çš„æ ‡å‡†å‘½ååˆ—è¡¨é‡Œï¼ˆæˆ–è€…æ˜¯ä¸ºäº†å…¼å®¹åŸå§‹æ•°æ®ï¼‰
    return [c for c in cols if not any(x in c.lower() for x in ['time', 'date', 'timestamp'])]

# =============================================================================
# 3. çŠ¶æ€ç®¡ç†
# =============================================================================

if 'sensor' not in st.session_state: st.session_state.sensor = 'strain'
if 'page' not in st.session_state: st.session_state.page = 'home'
if 'data_map' not in st.session_state: 
    st.session_state.data_map = {k: {'data': None, 'processed': None, 'meta': None} for k in SENSORS.keys()}

def get_current_data(): return st.session_state.data_map[st.session_state.sensor]
def set_current_data(data=None, processed=None, meta=None):
    if data is not None: st.session_state.data_map[st.session_state.sensor]['data'] = data
    if processed is not None: st.session_state.data_map[st.session_state.sensor]['processed'] = processed
    if meta is not None: st.session_state.data_map[st.session_state.sensor]['meta'] = meta

# =============================================================================
# 4. ç»˜å›¾é€»è¾‘
# =============================================================================

@st.cache_data(show_spinner=False)
def load_csv_data(path):
    return pd.read_csv(path)

def plot_paper_chart(df, col, color, title):
    fig = go.Figure()
    step = max(1, len(df) // 5000)
    
    time_col = None
    for c in df.columns:
        if any(x in c.lower() for x in ['time', 'date', 'timestamp']):
            time_col = c
            break
            
    x_data = df[time_col][::step] if time_col else df.index[::step]
    
    fig.add_trace(go.Scattergl(
        x=x_data, 
        y=df[col][::step], 
        mode='lines', 
        name=col,
        line=dict(color=color, width=1)
    ))
    fig.update_layout(title=f"{title} - {col}", height=350, margin=dict(l=40,r=20,t=40,b=30), plot_bgcolor='white', 
                     xaxis=dict(showgrid=True, gridcolor='#eee'),
                     yaxis=dict(showgrid=True, gridcolor='#eee'))
    return fig

def plot_comparison(orig, proc, color, col_name):
    fig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.1, 
                        subplot_titles=(f"Original: {col_name}", "Processed"))
    step = max(1, len(orig) // 5000)
    fig.add_trace(go.Scattergl(y=orig[::step], name='Raw', line=dict(color='#999', width=0.8)), row=1, col=1)
    fig.add_trace(go.Scattergl(y=proc[::step], name='Clean', line=dict(color=color, width=1.2)), row=2, col=1)
    fig.update_layout(height=500, margin=dict(l=40,r=20,t=40,b=20), plot_bgcolor='white', showlegend=False)
    fig.update_xaxes(showgrid=True, gridcolor='#eee')
    fig.update_yaxes(showgrid=True, gridcolor='#eee')
    return fig

# =============================================================================
# 5. ä¾§è¾¹æ ä¸é¡µé¢
# =============================================================================

def render_sidebar():
    with st.sidebar:
        st.markdown("<h3 style='text-align:center;'>ZHOU BRIDGE SHM</h3>", unsafe_allow_html=True)
        st.caption("SENSOR SELECTION")
        opts = list(SENSORS.keys())
        labels = [f"{SENSORS[k]['name']}" for k in opts]
        idx = st.radio("Sensor", range(len(opts)), format_func=lambda x: labels[x], label_visibility="collapsed")
        
        key = opts[idx]
        if key != st.session_state.sensor:
            st.session_state.sensor = key
            st.toast(f"å·²åˆ‡æ¢è‡³ {SENSORS[key]['name']}", icon="ğŸ”„")
            time.sleep(0.3)
            st.rerun()
            
        cur = SENSORS[key]
        st.info(f"**ç±»å‹:** {cur['name']}\n**æ ‡å‡†é€šé“æ•°:** {len(cur['channels'])}")
        st.markdown("---")
        st.caption("MODULES")
        nav = {'home': 'ğŸ  ç³»ç»Ÿæ¦‚è§ˆ', 'data': 'ğŸ“Š æ•°æ®ç®¡ç†', 'process': 'âš¡ æ™ºèƒ½å¤„ç†', 'export': 'ğŸ“¥ æˆæœå¯¼å‡º'}
        page = st.radio("Nav", list(nav.keys()), format_func=lambda x: nav[x], label_visibility="collapsed")
        return page

def page_home():
    st.title("ğŸ  ç³»ç»Ÿæ¦‚è§ˆ")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ä¼ æ„Ÿå™¨ç±»å‹", "4 ç±»")
    c2.metric("ç›‘æµ‹é€šé“æ€»æ•°", "8 ä¸ª", help="S-01~04, A-01~02, T-01, D-01")
    c3.metric("ç®—æ³•å¼•æ“", "Ready" if ALGO_STATUS else "Missing")
    total = sum([len(v['data']) if v['data'] is not None else 0 for v in st.session_state.data_map.values()])
    c4.metric("æ€»æ•°æ®é‡", f"{total:,}")
    
    st.markdown("---")
    cols = st.columns(4)
    for i, (k, s) in enumerate(SENSORS.items()):
        with cols[i]:
            has_data = st.session_state.data_map[k]['data'] is not None
            st.markdown(f"""
            <div class="card" style="border-top-color:{s['color']}; text-align:center;">
                <h1 style="font-size: 3em; margin: 0;">{s['icon']}</h1>
                <h4 style="margin: 10px 0;">{s['name']}</h4>
                <p style="font-size: 0.85em; color: #666;">{len(s['channels'])} ä¸ªé€šé“</p>
                <p style="color:{'#2ecc71' if has_data else '#95a5a6'}; font-weight: bold;">â— {'åœ¨çº¿' if has_data else 'ç¦»çº¿'}</p>
            </div>
            """, unsafe_allow_html=True)

def page_data():
    sensor_key = st.session_state.sensor
    s = SENSORS[sensor_key]
    store = get_current_data()
    st.title(f"ğŸ“Š æ•°æ®ç®¡ç† - {s['name']}")
    
    c1, c2 = st.columns([1, 2])
    
    with c1:
        st.markdown("### ğŸ“¥ æ•°æ®åŠ è½½")
        
        tab_auto, tab_manual = st.tabs(["ğŸ“‚ æ–‡ä»¶ / æ¼”ç¤º", "âœï¸ æ‰‹åŠ¨è¾“å…¥"])
        
        with tab_auto:
            st.caption(f"é¢„æœŸåŠ è½½æ–‡ä»¶: {s['file']}")
            if st.button("ğŸš€ åŠ è½½æ¼”ç¤ºæ•°æ®", type="primary", use_container_width=True):
                path = os.path.join(DATA_PATH, s['file'])
                if os.path.exists(path):
                    with st.spinner("è¯»å–å¹¶æ ‡å‡†åŒ–..."):
                        raw_df = load_csv_data(path)
                        # æ ¸å¿ƒæ­¥éª¤ï¼šæ ‡å‡†åŒ–åˆ—å
                        std_df = standardize_columns(raw_df, sensor_key)
                        set_current_data(data=std_df, processed=None)
                        st.success(f"å·²åŠ è½½å¹¶æ˜ å°„ {len(std_df)} è¡Œæ•°æ®")
                        time.sleep(0.5)
                        st.rerun()
                else:
                    st.error(f"æœªæ‰¾åˆ°æ–‡ä»¶: {s['file']}")

            st.markdown("---")
            uploaded = st.file_uploader("ä¸Šä¼  CSV", type=['csv'])
            if uploaded:
                try:
                    raw_df = pd.read_csv(uploaded)
                    std_df = standardize_columns(raw_df, sensor_key)
                    set_current_data(data=std_df)
                    st.success("ä¸Šä¼ å¹¶æ ‡å‡†åŒ–æˆåŠŸ")
                    st.rerun()
                except Exception as e:
                    st.error(f"è§£æå¤±è´¥: {e}")

        with tab_manual:
            st.info("è¯·è¾“å…¥ CSV æ•°æ® (è¡¨å¤´åç§°ä¸é‡è¦ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨æŒ‰é¡ºåºæ˜ å°„ä¸ºæ ‡å‡†é€šé“å)")
            
            # åŠ¨æ€ç”Ÿæˆç¬¦åˆå½“å‰ä¼ æ„Ÿå™¨é€šé“æ•°é‡çš„é»˜è®¤æ–‡æœ¬
            if sensor_key == 'strain':
                # 4é€šé“
                example = "timestamp,CH1,CH2,CH3,CH4\n2023-01-01,10.1,10.2,10.3,10.4\n2023-01-02,11.1,11.2,11.3,11.4"
            elif sensor_key == 'accel':
                # 2é€šé“
                example = "timestamp,CH1,CH2\n2023-01-01,0.01,0.02\n2023-01-02,0.03,0.01"
            else:
                # 1é€šé“
                example = "timestamp,CH1\n2023-01-01,25.5\n2023-01-02,26.1"
                
            manual_text = st.text_area("æ•°æ®è¾“å…¥åŒº", height=200, value=example)
            
            if st.button("è§£æå¹¶æ ‡å‡†åŒ–", use_container_width=True):
                if manual_text.strip():
                    try:
                        raw_df = pd.read_csv(io.StringIO(manual_text))
                        std_df = standardize_columns(raw_df, sensor_key)
                        set_current_data(data=std_df)
                        st.toast("æ•°æ®åŠ è½½æˆåŠŸ (åˆ—åå·²é‡ç½®)", icon="âœ…")
                        st.rerun()
                    except Exception as e:
                        st.error(f"æ ¼å¼é”™è¯¯: {e}")
                else:
                    st.warning("è¾“å…¥ä¸ºç©º")

    with c2:
        if store['data'] is not None:
            df = store['data']
            st.markdown("### ğŸ“ˆ æ•°æ®é¢„è§ˆ")
            st.dataframe(df.head(10), use_container_width=True)
            
            # --- æ ¸å¿ƒï¼šè¿™é‡Œçš„ cols ä¸€å®šæ˜¯æ ‡å‡†åŒ–åçš„ (strain_S-01_micro ç­‰) ---
            sensor_cols = get_display_columns(df)
            # å†æ¬¡æŒ‰åç§°æ’åºï¼Œç¡®ä¿ S-01, S-02 é¡ºåº
            sensor_cols.sort()
            
            if len(sensor_cols) > 0:
                col = st.selectbox("é€‰æ‹©ä¼ æ„Ÿå™¨é€šé“", sensor_cols)
                if col:
                    try:
                        st.plotly_chart(plot_paper_chart(df, col, s['color'], s['name']), use_container_width=True)
                    except Exception as e:
                        st.error(f"ç»˜å›¾é”™è¯¯: {e}")
            else:
                st.warning("æ•°æ®ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ•°æ®åˆ—")
        else:
            st.info("ğŸ‘ˆ è¯·å…ˆä»å·¦ä¾§åŠ è½½æ•°æ®")

def page_process():
    s = SENSORS[st.session_state.sensor]
    store = get_current_data()
    st.title(f"âš¡ æ™ºèƒ½å¤„ç† - {s['name']}")
    if store['data'] is None:
        st.warning("âš ï¸ è¯·å…ˆåŠ è½½æ•°æ®")
        return
    
    df = store['data']
    sensor_cols = get_display_columns(df)
    sensor_cols.sort()

    c1, c2 = st.columns([1, 2.5])
    with c1:
        st.markdown("### âš™ï¸ ç®—æ³•é…ç½®")
        if not sensor_cols:
            st.error("æ— å¯å¤„ç†é€šé“")
            return
        
        target = st.selectbox("1. ç›®æ ‡é€šé“", sensor_cols)
        st.markdown("---")
        fill = st.selectbox("2. ç¼ºå¤±å€¼å¤„ç†", ['spline', 'linear', 'polynomial', 'nearest'])
        anom = st.selectbox("3. å¼‚å¸¸æ£€æµ‹", ['sigma', 'iqr', 'mad', 'isolation_forest'])
        
        if anom == 'sigma': thresh = st.slider("é˜ˆå€¼ (n_sigma)", 1.0, 5.0, 3.0)
        elif anom == 'iqr': thresh = st.slider("é˜ˆå€¼ (k)", 1.0, 3.0, 1.5)
        else: thresh = st.slider("é˜ˆå€¼", 2.0, 5.0, 3.5)
        
        filt = st.selectbox("4. æ»¤æ³¢ç®—æ³•", ['wavelet', 'moving_average', 'gaussian', 'savgol'])
        st.markdown("---")
        
        if st.button("ğŸš€ è¿è¡Œå¤„ç†", type="primary", use_container_width=True):
            if not ALGO_STATUS:
                st.error("ç®—æ³•åº“ preprocessing_lib.py ç¼ºå¤±")
                return

            bar = st.progress(0, text="åˆå§‹åŒ–...")
            
            try:
                raw = pd.to_numeric(df[target], errors='coerce').values
                
                # Step 1
                bar.progress(30, text=f"å¡«è¡¥ ({fill})...")
                time.sleep(0.2)
                h = MissingValueHandler()
                s1 = h.fill_missing(raw, fill)
                
                # Step 2
                bar.progress(60, text=f"æ£€æµ‹å¼‚å¸¸ ({anom})...")
                time.sleep(0.2)
                d = AnomalyDetector()
                kw = {}
                if anom == 'sigma': kw['n_sigma'] = thresh
                elif anom == 'iqr': kw['k'] = thresh
                else: kw['threshold'] = thresh
                
                _, idx = d.detect_anomalies(s1, anom, **kw)
                s2 = d.replace_anomalies(s1, anom, 'interpolation', **kw)
                
                # Step 3
                bar.progress(85, text=f"å»å™ª ({filt})...")
                time.sleep(0.2)
                f = NoiseFilter()
                s3 = f.filter_signal(s2, filt)
                snr = PerformanceMetrics.calculate_snr(s2, s3)
                
                bar.progress(100, text="å®Œæˆ")
                time.sleep(0.5)
                bar.empty()
                
                meta = {
                    'col': target,
                    'params': {'fill': fill, 'anom': anom, 'filt': filt},
                    'stats': {'idx': len(idx), 'snr': snr},
                    'original': raw
                }
                set_current_data(processed=s3, meta=meta)
                st.toast("å¤„ç†æˆåŠŸ", icon="âœ…")
                
            except Exception as e:
                st.error(f"é”™è¯¯: {e}")
                st.code(traceback.format_exc())

    with c2:
        if store['processed'] is not None:
            res = store['meta']
            if res.get('col') != target:
                st.warning("âš ï¸ ç»“æœæœªæ›´æ–°ï¼Œè¯·ç‚¹å‡»è¿è¡Œ")
            
            proc = store['processed']
            orig = res['original']
            
            st.markdown("### ğŸ“ˆ ç»“æœåˆ†æ")
            k1, k2, k3 = st.columns(3)
            k1.metric("å¼‚å¸¸ç‚¹", f"{res['stats']['idx']}", delta="Detected")
            k2.metric("SNR", f"{res['stats']['snr']:.2f} dB", delta="Quality")
            k3.metric("é€šé“", target)
            
            st.plotly_chart(plot_comparison(orig, proc, s['color'], target), use_container_width=True)
        else:
            st.info("ğŸ‘ˆ è¯·è¿è¡Œç®—æ³•")

def page_export():
    s_info = SENSORS[st.session_state.sensor]
    store = get_current_data()
    st.title(f"ğŸ“¥ æˆæœå¯¼å‡º - {s_info['name']}")
    if store['processed'] is None:
        st.warning("âš ï¸ æ— å¤„ç†ç»“æœ")
        return
        
    res = store['meta']
    proc = store['processed']
    col_name = res.get('col', 'data')
    
    c1, c2 = st.columns(2)
    with c1:
        st.markdown("### ğŸ’¾ å¯¼å‡º CSV")
        df_out = pd.DataFrame({
            f'Raw_{col_name}': res['original'], 
            f'Clean_{col_name}': proc
        })
        csv = df_out.to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½æ•°æ® (CSV)",
            data=csv,
            file_name=f"Result_{col_name}.csv",
            mime="text/csv",
            type="primary"
        )
    with c2:
        st.markdown("### ğŸ“„ å¯¼å‡ºæŠ¥å‘Š")
        rpt = f"""ç›‘æµ‹æŠ¥å‘Š\né€šé“: {col_name}\nå¼‚å¸¸ç‚¹: {res['stats']['idx']}\nSNR: {res['stats']['snr']:.2f} dB\nç»“è®º: æ­£å¸¸"""
        st.text_area("é¢„è§ˆ", rpt, height=200)
        st.download_button("ğŸ“¥ ä¸‹è½½æŠ¥å‘Š (TXT)", rpt, f"Report_{col_name}.txt")

def main():
    apply_style()
    page = render_sidebar()
    if page == 'home': page_home()
    elif page == 'data': page_data()
    elif page == 'process': page_process()
    elif page == 'export': page_export()

if __name__ == "__main__":
    main()
